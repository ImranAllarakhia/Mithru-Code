{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AI LiDAR Load in Program**"
      ],
      "metadata": {
        "id": "wtt9tErNf2QK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import Librararies:**\n",
        "\n",
        "Ensure when importing the Libraries that you have already installed them  "
      ],
      "metadata": {
        "id": "VVFXoa3Sf-t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "50ROyJsHgVI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extract The Local Zip Files:**\n",
        "\n",
        "This progarm first analzyes whether not a folder exists or not, and creates the folder if it didn't already exist. Then you extract the files in the directory and have a progress bar for tracking its progress\n"
      ],
      "metadata": {
        "id": "QzekPcTigXYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_local_zip(zip_path, extract_path):\n",
        "    # Check if the zip file exists\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Error: Zip file not found at {zip_path}\")\n",
        "        return\n",
        "\n",
        "    # Create the extraction directory if it doesn't exist\n",
        "    if not os.path.exists(extract_path):\n",
        "        os.makedirs(extract_path)\n",
        "\n",
        "    try:\n",
        "        # Extract the contents of the zip file with tqdm progress bar\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            # Handle the case where the zip file contains a single directory\n",
        "            file_list = zip_ref.namelist()\n",
        "            for file in tqdm(file_list, desc=\"Extracting\"):\n",
        "                zip_ref.extract(file, extract_path)\n",
        "\n",
        "        print(\"Zip file extracted successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting zip file: {e}\")\n"
      ],
      "metadata": {
        "id": "f2CxgQgOgyw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Augment the Dataset for Usage**\n",
        "\n",
        "First we create the folder for the augmented_folder and if it already exists,ignores the creation. Then we format the images use the ImageDataGenrator function. Then we add the funal touches the generate the data, and format it perfectly for AI. FInally the tqdm bar is defined\n",
        "\n"
      ],
      "metadata": {
        "id": "Mvhfca63h2lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_augment_dataset(extract_path, augmented_path, target_image_size=(224, 224), batch_size=16, total_augmented_images=None):\n",
        "    # Create the augmented images directory if it doesn't exist\n",
        "    if not os.path.exists(augmented_path):\n",
        "        os.makedirs(augmented_path)\n",
        "\n",
        "    # Create an ImageDataGenerator with your desired parameters\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=45,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        width_shift_range=0.15,\n",
        "        height_shift_range=0.15,\n",
        "        shear_range=0.2,\n",
        "        rescale=1./255  # Added rescaling to normalize pixel values\n",
        "    )\n",
        "\n",
        "    # Create a generator from the data in the extracted path\n",
        "    generator = datagen.flow_from_directory(\n",
        "        extract_path,\n",
        "        target_size=target_image_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        save_to_dir=augmented_path,  # Save the augmented images to the specified directory\n",
        "        save_prefix='augmented',\n",
        "        save_format='png'\n",
        "    )\n",
        "\n",
        "    # Determine the total number of images to augment\n",
        "    total_images = min(total_augmented_images, generator.samples) if total_augmented_images else generator.samples\n",
        "\n",
        "    # Create the augmented images with tqdm progress bar\n",
        "    for _ in tqdm(range(total_images), desc=\"Augmenting\"):\n",
        "        try:\n",
        "            next(generator)\n",
        "        except StopIteration:\n",
        "            break  # Stop if the generator has no more data\n",
        "\n",
        "    print(f\"{total_images} images in the folder augmented and saved successfully.\")\n"
      ],
      "metadata": {
        "id": "Gbn5blQwk7TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main Program/ Running**\n",
        "We define our three paths and run the functions"
      ],
      "metadata": {
        "id": "gfHh1sN-k_Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "zip_file = r\"C:\\\\Users\\\\allar\\\\Downloads\\\\data_object_image_2.zip\"\n",
        "extracted_path = r\"C:\\\\Users\\\\allar\\\\Downloads\\\\extracted_data\"  # Update the directory path\n",
        "augmented_path = r\"C:\\\\Users\\\\allar\\\\Downloads\\\\augmented_data\"  # Update the directory path\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "extract_local_zip(zip_file, extracted_path)\n",
        "\n",
        "# Create and augment the dataset\n",
        "create_and_augment_dataset(extracted_path, augmented_path, target_image_size=(224, 224), batch_size=16, total_augmented_images=None)\n"
      ],
      "metadata": {
        "id": "7-Kzx859lHUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
